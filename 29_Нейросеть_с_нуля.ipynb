{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqoODgiHRJmC"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A4DGbVTUK9Z"
      },
      "source": [
        "# Что такое искусственный нейрон?\n",
        "\n",
        "Икусственный нейрон - это всего лишь комбинация математических операций. Вектор чисел (входные данные) умножатеся на вектор коэффициентов (имено они как раз и \"обучаются\"); их произведения суммируются и поступают на вход функции активации, которая трансформируется в результат.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1yFPLGhmGgBQ-pxEtWqw_3YemSwlFU-XT)\n",
        "\n",
        "Обобщенная формула искусственного, получается, выглядит следующим образом:\n",
        "$$y = f(\\sum_{i=1}^n x_i*w_i + b)$$\n",
        "\n",
        "В качестве функции активации может выстпать любая функция. До недавнего широкого распространения свёрточных нейронных сетей наиболее часто использовалась сигмоида. Сейчас - так называемая RELU-функция. Мы на данном вебинаре реализуем в первую очередь сигмоиду (она показана на картинке). Но код легко будет заменить на любой необходимый.\n",
        "\n",
        "![Сигмоида](https://python-scripts.com/wp-content/uploads/2019/10/neural-networks-10.jpg)\n",
        "\n",
        "Формула функции сигмоиды: $$y = \\frac{1}{(1+e^{-x})}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMKzQhtAt3Gh"
      },
      "source": [
        "# Создаём свой нейрон"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP5V9n5nR5fy"
      },
      "source": [
        "# определеним функцию (в языке программирования) для вычислени значения функции (математика) с использованием формулы сигмоиды\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4nqYpv3Rnbw"
      },
      "source": [
        "# создаём класс для нейрона\n",
        "\n",
        "class Neuron:\n",
        "\n",
        "# в конструктор передаём значения весов и смещения\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "#создаём метод класса для описания процедуры прямого прохождения сигнала\n",
        "    def feedforward(self, inputs):\n",
        "        #np.dot обеспечивает перемножение векторов\n",
        "        result = np.dot(self.weights, inputs) + self.bias\n",
        "        return sigmoid(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgybrygsRzR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691bab0e-9326-4cb3-d19c-3224f5cf9c38"
      },
      "source": [
        "# посмотрим простой пример w1 = 0, w2 = 1, b = 1\n",
        "\n",
        "weights = np.array([1, 1])\n",
        "bias = 1\n",
        "\n",
        "#создаём нейрон, активируем конструктор\n",
        "n = Neuron(weights, bias)\n",
        "\n",
        "#заданим входные данные Х - x1 = 1, x2 = 1\n",
        "\n",
        "x = np.array([1, 1])\n",
        "print(n.feedforward(x))\n",
        "print((1/(1+np.exp(-3))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9525741268224334\n",
            "0.9525741268224334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHlUQ4cAtohr"
      },
      "source": [
        "# Что такой нейронная сеть?\n",
        "\n",
        "Нейронная сеть - группа связанных между собой нейронов. Классические сети - полносязные. Бывают и другие. Есть три типа слоёв:\n",
        "\n",
        "*   Входной - принимает на вход сигналы\n",
        "*   Скрытые - \"рабочие\" слои, преобразуют входные данные в выходные\n",
        "*   Выходной - позволяет считать результат\n",
        "\n",
        "Количество нейроннов в каждом слое зависит от желания \"автора\" той или иной сети.\n",
        "\n",
        "Мы будем делать очень простую сетку - она на вход будет принимать две сигнала и сразу передавать результат обработки на выход.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1ooVWuapuohvaAvvOa_MGfKRdDy4NA8Ta)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmt2vbn7w9ln"
      },
      "source": [
        "# Создаём свою нейросеть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI7yPR2FSJCD"
      },
      "source": [
        "class NeuralNetwork:\n",
        "\n",
        "# создаём констурктор для класса нейросети\n",
        "# пока что все нейронны имеют одинаковые параметры\n",
        "    def __init__(self):\n",
        "        weights = np.array([0, 1])\n",
        "        bias = 0\n",
        "\n",
        "        # Класс Neuron из предыдущего раздела\n",
        "        self.n1 = Neuron(weights, bias)\n",
        "        self.n2 = Neuron(weights, bias)\n",
        "        self.o1 = Neuron(weights, bias)\n",
        "\n",
        "    def feedforward(self, x):\n",
        "        #считаем результат для первого нейрона\n",
        "        out_n1 = self.n1.feedforward(x)\n",
        "        #считаем результат для второго нейрона\n",
        "        out_n2 = self.n2.feedforward(x)\n",
        "\n",
        "        # Входы для о являются выводами h1 и h2\n",
        "        out_o = self.o1.feedforward(np.array([out_n1, out_n2]))\n",
        "\n",
        "        return out_o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu_nVZgGTKj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070feeff-fb51-45a4-cecb-51f55da97642"
      },
      "source": [
        "network = NeuralNetwork()\n",
        "x = np.array([2, 3])\n",
        "print(network.feedforward(x))  # 0.7216325609518421\n",
        "print((1/(1+np.exp(-3)))) # n1 и n2\n",
        "print((1/(1+np.exp(-0.952574)))) # o"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7216325609518421\n",
            "0.9525741268224334\n",
            "0.7216325354758769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLTVDbpXL-Mq"
      },
      "source": [
        "# Создать мало - нужно тренировать. Считаем точность\n",
        "\n",
        "Создать нейронную сеть не досаточно. Необходимо подобрать такие значения коэффициентов и смещения, которые ползволят добиться наиболее точных результатов.\n",
        "\n",
        "Для начала разберём, как посчитать точность результатов.\n",
        "\n",
        "Предположим, что есть текущие результаты, предсказанные нейронной сетью $y_{pred}$ и истинные значения $y_{true}$. Известный способ подсчитать ошибку - сумма квадратов отклонений.\n",
        "\n",
        "$$MSE = (y_{true}-y_{pred})^{2} / n $$\n",
        "\n",
        "Для понимания можно посомтреть график.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1y6Rbh9Pn7q8J78dy0wnjN5uaCeDfWs0q)\n",
        "\n",
        "Основная задача при обучении - минимизировать эту сумму.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0DETl_aTPkG"
      },
      "source": [
        "def mse_loss(y_true, y_pred):\n",
        "    # y_true и y_pred являются массивами numpy с одинаковой длиной\n",
        "    return ((y_true - y_pred) ** 2).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inTWdpanTTx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ae762aa-bdc2-4a7e-9679-ee01b84eeab5"
      },
      "source": [
        "# для примера\n",
        "\n",
        "y_true = np.array([1, 0, 0, 1])\n",
        "y_pred = np.array([0, 0, 0, 0])\n",
        "\n",
        "print(mse_loss(y_true, y_pred))  # 0.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WnMfzSISogz"
      },
      "source": [
        "# Создать мало - нужно тренировать. Как тренировать?\n",
        "\n",
        "Схема обучения - простая. Нам необходимы взять исходные данные с известным результатом. Подаём на вход исходные данные, смотрим результат, меняем значения коэффициентов нейроннов, и так далее.\n",
        "\n",
        "### Здесь далее будет \"сложная\" математика. К сожалению без неё ни как.\n",
        "\n",
        "Итак, предположим, что вся наша нейронная сеть - это функция от коэффициентов и сммещения (3 нейрона)\n",
        "\n",
        "$ L(w_{всенейроны},b_{всенейроны}) = L(w_1, w_2, w_3, w_4, w_5, w_6, b_1, b_2, b_3)$\n",
        "\n",
        "Производные считаем через частные произодные для любого из коэффициентов, например для $ w_1 $\n",
        "\n",
        "$ \\partial L/\\partial w_1 = \\partial L/\\partial y_{pred} * \\partial y_{pred}/\\partial w_1 $\n",
        "\n",
        "$ \\partial L/\\partial y_{pred} = -2(y_{true} - y_{pred})$\n",
        "\n",
        "Значение $y_{true}$ мы в каждом конкретном случае знаем.\n",
        "\n",
        "$ \\partial y_{pred}/\\partial w_1 = \\partial y_{pred}/\\partial n_{1} * \\partial n_{1}/\\partial w_1 $\n",
        "\n",
        "$ \\partial y_{pred}/\\partial n_{1} = w_5 f'(w_5*n_1 + w_6*n_2+b_3) $\n",
        "\n",
        "$ \\partial n_{1}/\\partial w_1 = x_1 f'(w_1*x_1 + w_2*x_2+b_1) $\n",
        "\n",
        "Осталось только для удобства рассчитать производную от известной нам функции - сигмоиды. Поверьте мне на слово)\n",
        "\n",
        "$ f'(x) = (1-f(x))*f(x)$\n",
        "\n",
        "Сейчас мы посчитали ошибку **методом обратного распространения ошибки**.\n",
        "\n",
        "Разбавим картикной для совсем более явного пояснения:\n",
        "\n",
        "![alt text](https://ok-t.ru/studopedia/baza7/1364490912182.files/image115.gif)\n",
        "\n",
        "Осталось только определить, как считаем изменненные значения коэффициентов и смещений:\n",
        "\n",
        "$ w_1 = w_1 - k * \\partial L /\\partial w_1 $\n",
        "\n",
        "$ k $ - задаётся человеком и определяет скорость **градиенного спуска**. Его смысл в том, что изменяем коэффициент в сторону убывания производной.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPVW-HsZTt2A"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def deriv_sigmoid(x):\n",
        "    fx = sigmoid(x)\n",
        "    return fx * (1 - fx)\n",
        "\n",
        "class NeuralNetwork:\n",
        "\n",
        "    def __init__(self):\n",
        "        # Вес задаём случайно для начала\n",
        "        self.w1 = np.random.normal()\n",
        "        self.w2 = np.random.normal()\n",
        "        self.w3 = np.random.normal()\n",
        "        self.w4 = np.random.normal()\n",
        "        self.w5 = np.random.normal()\n",
        "        self.w6 = np.random.normal()\n",
        "\n",
        "        # Смещения задаём случайно для начала\n",
        "        self.b1 = np.random.normal()\n",
        "        self.b2 = np.random.normal()\n",
        "        self.b3 = np.random.normal()\n",
        "\n",
        "    def feedforward(self, x):\n",
        "        # прямой ход\n",
        "        n1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
        "        n2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
        "        o1 = sigmoid(self.w5 * n1 + self.w6 * n2 + self.b3)\n",
        "        return o1\n",
        "\n",
        "    def train(self, data, all_y_trues):\n",
        "\n",
        "        learn_rate = 200 # коэффициент k\n",
        "        epochs = 1000 # количество циклов во всём наборе данных\n",
        "\n",
        "        loss_row = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for x, y_true in zip(data, all_y_trues):\n",
        "                # Прямой ход с сохранением дополнительных значений\n",
        "                sum_n1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
        "                n1 = sigmoid(sum_n1)\n",
        "\n",
        "                sum_n2 = self.w3 * x[0] + self.w4 * x[1] + self.b2\n",
        "                n2 = sigmoid(sum_n2)\n",
        "\n",
        "                sum_o1 = self.w5 * n1 + self.w6 * n2 + self.b3\n",
        "                o1 = sigmoid(sum_o1)\n",
        "                y_pred = o1\n",
        "\n",
        "                # --- Подсчет частных производных\n",
        "                # --- Наименование: d_L_d_w1 представляет \"частично L / частично w1\"\n",
        "                d_L_d_ypred = -2 * (y_true - y_pred)\n",
        "\n",
        "                # Нейрон o1\n",
        "                d_ypred_d_w5 = n1 * deriv_sigmoid(sum_o1)\n",
        "                d_ypred_d_w6 = n2 * deriv_sigmoid(sum_o1)\n",
        "                d_ypred_d_b3 = deriv_sigmoid(sum_o1)\n",
        "\n",
        "                d_ypred_d_n1 = self.w5 * deriv_sigmoid(sum_o1)\n",
        "                d_ypred_d_n2 = self.w6 * deriv_sigmoid(sum_o1)\n",
        "\n",
        "                # Нейрон n1\n",
        "                d_h1_d_w1 = x[0] * deriv_sigmoid(sum_n1)\n",
        "                d_h1_d_w2 = x[1] * deriv_sigmoid(sum_n1)\n",
        "                d_h1_d_b1 = deriv_sigmoid(sum_n1)\n",
        "\n",
        "                # Нейрон n2\n",
        "                d_h2_d_w3 = x[0] * deriv_sigmoid(sum_n2)\n",
        "                d_h2_d_w4 = x[1] * deriv_sigmoid(sum_n2)\n",
        "                d_h2_d_b2 = deriv_sigmoid(sum_n2)\n",
        "\n",
        "                # --- Обновляем вес и смещения\n",
        "                # Нейрон n1\n",
        "                self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_n1 * d_h1_d_w1\n",
        "                self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_n1 * d_h1_d_w2\n",
        "                self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_n1 * d_h1_d_b1\n",
        "\n",
        "                # Нейрон n2\n",
        "                self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_n2 * d_h2_d_w3\n",
        "                self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_n2 * d_h2_d_w4\n",
        "                self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_n2 * d_h2_d_b2\n",
        "\n",
        "                # Нейрон o1\n",
        "                self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_w5\n",
        "                self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_w6\n",
        "                self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
        "\n",
        "            # --- Подсчитываем общую потерю в конце каждой фазы\n",
        "            if epoch % 10 == 0:\n",
        "                y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
        "                loss = mse_loss(all_y_trues, y_preds)\n",
        "                loss_row.append(loss)\n",
        "                #print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
        "        return loss_row\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emvtGF3whLil"
      },
      "source": [
        "# Тестируем нейронную сеть\n",
        "\n",
        "Определяем пол по росту и весу"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91aC-rmOT1JM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "cd78578c-79ad-4931-ca5c-f31e1273bfec"
      },
      "source": [
        "# Определение набора данных\n",
        "data = np.array([\n",
        "    [57, 165],     # Алиса\n",
        "    [78, 183],     # Боб\n",
        "    [92, 190],     # Иван\n",
        "    [52, 172],     # Марья\n",
        "])\n",
        "\n",
        "\n",
        "mean_weight = (92+78+57+52)/4\n",
        "\n",
        "mean_height = (165+183+190+172)/4\n",
        "\n",
        "#data = np.array([\n",
        "#    [57-int(mean_weight), 165-int(mean_height)],     # Алиса\n",
        "#    [78-int(mean_weight), 183-int(mean_height)],     # Боб\n",
        "#    [92-int(mean_weight), 190-int(mean_height)],     # Иван\n",
        "#    [52-int(mean_weight), 172-int(mean_height)],     # Марья\n",
        "#])\n",
        "\n",
        "\n",
        "#print(data)\n",
        "\n",
        "all_y_trues = np.array([\n",
        "    1, # Алиса\n",
        "    0, # Боб\n",
        "    0, # Иван\n",
        "    1, # Марья\n",
        "])\n",
        "\n",
        "# Тренируем нашу нейронную сеть!\n",
        "network = NeuralNetwork()\n",
        "loss = network.train(data, all_y_trues)\n",
        "\n",
        "plt.figure(figsize = (8, 8))\n",
        "plt.plot(loss)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5si5QiHT48K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43372903-d845-4606-ad8e-2d7ac4122141"
      },
      "source": [
        "w_name = np.array([55, 160])\n",
        "\n",
        "w_name[0] = w_name[0] - mean_weight\n",
        "w_name[1] = w_name[1] - mean_height\n",
        "\n",
        "m_name = np.array([72, 190])\n",
        "\n",
        "m_name[0] = m_name[0] - mean_weight\n",
        "m_name[1] = m_name[1] - mean_height\n",
        "\n",
        "print(f\"Женщина: {network.feedforward(w_name)}\")\n",
        "print(f\"Мужчина: {network.feedforward(m_name)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Женщина: 1.0\n",
            "Мужчина: 1.0\n"
          ]
        }
      ]
    }
  ]
}